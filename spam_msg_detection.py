# -*- coding: utf-8 -*-
"""Spam_msg_detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ospWcTcmG2sVj_7Ch9xeA4g3RRuSCFR_
"""

import nltk

import numpy as np
import pandas as pd

messages = [line.rstrip() for line in open('/content/SMSSpamCollection')]

print(len(messages))

messages[50]

messages[0]

for mess_no, message in enumerate(messages[:10]):
    print(mess_no, message)
    print('\n')

messages[0]

messages = pd.read_csv('/content/SMSSpamCollection', sep = '\t', names = ['label', 'message'])

messages.head()

messages.describe()

messages.groupby('label').describe()

messages['length'] = messages['message'].apply(len)

messages.head()

import matplotlib.pyplot as plt
import seaborn as sns

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

messages['length'].plot.hist(bins =50)

messages['length'].describe()

messages[messages['length']==910]['message'].iloc[0]

messages.hist(column = 'length', by= 'label', bins = 60, figsize= (12,4))

"""Observation: Spam msgs tend to have more msgs than ham!!!

Thus length can be a good parameter to differnetiate between spam and ham. :-)

Feature vectors will be needed for the classification.
"""

import string

mess = 'Sample message! Notice: it has punctuation.'

string.punctuation

nopunc = [c for c in mess if c not in string.punctuation]

nopunc

nltk.download_shell()

from nltk.corpus import stopwords

stopwords.words('english')

nopunc = ''.join(nopunc)

nopunc

nopunc.split()

clean_mess = [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]

clean_mess

def text_process(mess):
  '''
  1. remove punctuation
  2. remove stop words
  3. return list of clean text words
  '''

  nopunc = [ char for char in mess if char not in string.punctuation]
  nopunc = ''.join(nopunc)

  return  [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]

messages.head()

messages['message'].head(5).apply(text_process)

### term frequency

from sklearn.feature_extraction.text import CountVectorizer

"""Bag of word approach"""

bow_transformer = CountVectorizer(analyzer = text_process).fit(messages['message'])

print(len(new_transformer.vocabulary_))

mess4 = messages['message'][3]

print(mess4)

bow4 = bow_transformer.transform([mess4])

print(bow4)

print(bow4.shape)

messages_bow = bow_transformer.transform(messages['message'])

print('Shape of spare matrix: ', messages_bow.shape)

messages_bow.nnz

sparsity = (100.0 * messages_bow.nnz / (messages_bow.shape[0] * messages_bow.shape[1]))
print('sparsity: {}'.format(round(sparsity)))

sparsity = (100.0 * messages_bow.nnz / (messages_bow.shape[0] * messages_bow.shape[1]))
print('sparsity: {}'.format(sparsity))

from sklearn.feature_extraction.text import TfidfTransformer

tfidf_transformer = TfidfTransformer().fit(messages_bow)

tfidf4 = tfidf_transformer.transform(bow4)

print(tfidf4)

tfidf_transformer.idf_[bow_transformer.vocabulary_['university']]

messages_tfidf = tfidf_transformer.transform(messages_bow)

"""Training and Classification using Naive Bayes Classifier"""

from sklearn.naive_bayes import MultinomialNB

spam_detect_model = MultinomialNB().fit(messages_tfidf, messages['label'])

spam_detect_model.predict(tfidf4)

spam_detect_model.predict(tfidf4)[0]

messages['label'][3]

all_pred = spam_detect_model.predict(messages_tfidf)

all_pred

"""NOTE: We trained everything on our training data. This is not good for evaluation. Data should be split in test set and training set equally."""

from sklearn.model_selection import train_test_split

msg_train, msg_test, label_train, label_test = train_test_split(messages['message'], messages['label'], test_size = 0.3)

msg_train

from sklearn.pipeline import Pipeline

pipeline = Pipeline([
    ('bow', CountVectorizer(analyzer=text_process)),
    ('tfidf', TfidfTransformer()),
    ('classifier', MultinomialNB())
])

pipeline.fit(msg_train, label_train)

predictions = pipeline.predict(msg_test)

from sklearn.metrics import classification_report

print(classification_report(label_test, predictions))

"""We have an accuracy of 96% on the test data!!!"""